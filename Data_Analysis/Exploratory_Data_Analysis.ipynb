{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{LIBRARIES}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_print(): print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_name', 'state', 'city', 'agency', 'station_location',\n",
      "       'start_month', 'start_month_num', 'start_year'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "  file_name           state        city agency          station_location  \\\n",
      "0     AP001  Andhra Pradesh    Tirupati  APPCB       Tirumala, Tirupati    \n",
      "1     AP002  Andhra Pradesh  Vijayawada  APPCB  PWD Grounds, Vijayawada    \n",
      "\n",
      "  start_month  start_month_num  start_year  \n",
      "0        July                7        2016  \n",
      "1         May                5        2017  \n"
     ]
    }
   ],
   "source": [
    "df_states = pd.read_csv(path + 'stations_info.csv')\n",
    "print(df_states.columns)\n",
    "\n",
    "sep_print()\n",
    "print(df_states.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a lot of data, so we're going to choose only one state for analysis. \n",
    "I'm looking for the state that has the minimum number of agencies (since each agency can have different measurements or column names for the same feature, choosing one will be easier), the most data available, and a similar number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dict = dict()\n",
    "max_dict = dict()\n",
    "min_dict = dict()\n",
    "\n",
    "for i in os.listdir(path):\n",
    "\n",
    "    if not i.endswith(\".csv\"):\n",
    "        next\n",
    "\n",
    "    prefix = i[:2]\n",
    "    val = pd.read_csv(path + i, nrows= 1).shape[1]\n",
    "\n",
    "    if prefix in sum_dict:\n",
    "            sum_dict[prefix] += val\n",
    "            max_dict[prefix] = val if max_dict[prefix] < val else  max_dict[prefix]\n",
    "            min_dict[prefix] = val if min_dict[prefix] > val else  min_dict[prefix]\n",
    "    else:\n",
    "        sum_dict[prefix] = val\n",
    "        max_dict[prefix] = val\n",
    "        min_dict[prefix] = val\n",
    "\n",
    "#Number of all columns in each state and max/ min number of column\n",
    "smm_df = pd.DataFrame({'sum': sum_dict.values(), 'min': min_dict.values(), 'max': max_dict.values()}, index=sum_dict.keys()).sort_values(by= [\"sum\", \"min\", \"max\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             count_agency  count_csv  sum  min  max\n",
      "file_name state                                                    \n",
      "HP        Himachal Pradesh              1          1   23   23   23\n",
      "JK        Jammu and Kashmir             1          1   23   23   23\n",
      "MZ        Mizoram                       1          1   23   23   23\n",
      "NL        Nagaland                      1          1   23   23   23\n",
      "SK        Sikkim                        1          1   24   24   24\n",
      "AR        Arunachal Pradesh             1          1   25   25   25\n",
      "PY        Puducherry                    1          1   25   25   25\n",
      "JH        Jharkhand                     1          2   29   10   19\n",
      "TR        Tripura                       1          2   47   23   24\n",
      "MN        Manipur                       1          2   48   24   24\n",
      "ML        Meghalaya                     1          2   49   24   25\n",
      "UK        Uttarakhand                   1          3   66   16   25\n",
      "CH        Chandigarh                    1          3   70   23   24\n",
      "KL        Kerala                        1          9  176   15   22\n",
      "AS        Assam                         1          9  206   22   24\n",
      "AP        Andhra Pradesh                1         10  241   23   25\n",
      "OR        Odisha                        1         12  233    9   24\n",
      "TG        Telangana                     1         14  319   20   23\n",
      "WB        West Bengal                   1         14  338   20   26\n",
      "BR        Bihar                         1         35  818   20   25\n",
      "RJ        Rajasthan                     1         35  818   22   24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiktor_PC\\AppData\\Local\\Temp\\ipykernel_11076\\3135209361.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_states_sub[\"file_name\"] = df_states_sub[\"file_name\"].apply(lambda x: x[:2])\n"
     ]
    }
   ],
   "source": [
    "#Number of diffrent agencies that measure air quility and how many .csv\n",
    "df_states_sub = df_states[[\"file_name\", \"state\", \"agency\"]]\n",
    "df_states_sub[\"file_name\"] = df_states_sub[\"file_name\"].apply(lambda x: x[:2])\n",
    "\n",
    "df_states_sub_info = df_states_sub[[\"file_name\", \"state\", \"agency\"]].drop_duplicates().groupby([\"file_name\", \"state\"]).count()\n",
    "df_states_sub_info = df_states_sub_info.join(\n",
    "                pd.value_counts(df_states[\"state\"]),\n",
    "                on = \"state\"\n",
    "            ).join(\n",
    "                smm_df,\n",
    "                on = \"file_name\"\n",
    "            )\n",
    "\n",
    "#Column rename\n",
    "df_states_sub_info.columns = ['count_agency', 'count_csv', 'sum', 'min', 'max']\n",
    "\n",
    "#Combining all created data\n",
    "df_states_sub_info = df_states_sub_info.sort_values(['count_agency', 'count_csv', 'sum', 'min', 'max'], kind= 'heapsort')\n",
    "print(df_states_sub_info[df_states_sub_info.count_agency == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output, I chose Andhra Pradesh state. The reason is that this state has 10 .csv files with 23 to 25 columns of data. Rajasthan state could work too, but my laptop wouldn't have been able to manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_name           state        city  start_month_num  start_year\n",
      "0     AP001  Andhra Pradesh    Tirupati                7        2016\n",
      "1     AP002  Andhra Pradesh  Vijayawada                5        2017\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_states.drop(columns= [\"agency\", \"station_location\", \"start_month\"], inplace= True)\n",
    "except:\n",
    "    pass\n",
    "print(df_states.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tirupati', 'Vijayawada', 'Visakhapatnam', 'Rajamahendravaram',\n",
       "       'Amaravati', 'Anantapur', 'Chittoor', 'Kadapa'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states[df_states['state'] == 'Andhra Pradesh'].city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am working with a large dataset that is split into multiple files. First, I will create a function that will return a dataframe combining all datasheets' measurements in a given state, so we can see what data we're working with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_state_file(state_name: str):\n",
    "    file_name_short = df_states_sub[df_states_sub[\"state\"] == state_name][\"file_name\"]\n",
    "\n",
    "    global path\n",
    "    combined_df = list()\n",
    "\n",
    "    print(f\"Combining a total of {len(file_name_short)} files\")\n",
    "\n",
    "    file_name_short = file_name_short.iloc[0]\n",
    "\n",
    "    for file in  os.listdir(path):\n",
    "        if file_name_short in file:\n",
    "            print(file)\n",
    "\n",
    "            file_data = pd.read_csv(path + file)\n",
    "            file_data[\"city\"] = df_states[df_states[\"file_name\"] == file[:-4]][\"city\"].values[0]\n",
    "            file_data[\"city\"] = file_data[\"city\"].astype(\"string\")\n",
    "\n",
    "            combined_df.append(file_data)\n",
    "\n",
    "    return pd.concat(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining a total of 10 files\n",
      "AP001.csv\n",
      "AP002.csv\n",
      "AP003.csv\n",
      "AP004.csv\n",
      "AP005.csv\n",
      "AP006.csv\n",
      "AP007.csv\n",
      "AP008.csv\n",
      "AP009.csv\n",
      "AP010.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 272217 entries, 0 to 1592\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   From Date            272217 non-null  object \n",
      " 1   To Date              272217 non-null  object \n",
      " 2   PM2.5 (ug/m3)        215379 non-null  float64\n",
      " 3   PM10 (ug/m3)         218510 non-null  float64\n",
      " 4   NO (ug/m3)           220857 non-null  float64\n",
      " 5   NO2 (ug/m3)          220797 non-null  float64\n",
      " 6   NOx (ppb)            222419 non-null  float64\n",
      " 7   NH3 (ug/m3)          216850 non-null  float64\n",
      " 8   SO2 (ug/m3)          217459 non-null  float64\n",
      " 9   CO (mg/m3)           219063 non-null  float64\n",
      " 10  Ozone (ug/m3)        214914 non-null  float64\n",
      " 11  Benzene (ug/m3)      221629 non-null  float64\n",
      " 12  Toluene (ug/m3)      221602 non-null  float64\n",
      " 13  Temp (degree C)      166170 non-null  float64\n",
      " 14  RH (%)               223812 non-null  float64\n",
      " 15  WS (m/s)             220464 non-null  float64\n",
      " 16  WD (deg)             71726 non-null   float64\n",
      " 17  SR (W/mt2)           221091 non-null  float64\n",
      " 18  BP (mmHg)            165564 non-null  float64\n",
      " 19  VWS (m/s)            206891 non-null  float64\n",
      " 20  Xylene (ug/m3)       168922 non-null  float64\n",
      " 21  RF (mm)              225060 non-null  float64\n",
      " 22  AT (degree C)        223117 non-null  float64\n",
      " 23  city                 272217 non-null  string \n",
      " 24  Eth-Benzene (ug/m3)  39909 non-null   float64\n",
      " 25  MP-Xylene (ug/m3)    105286 non-null  float64\n",
      " 26  O Xylene (ug/m3)     22338 non-null   float64\n",
      " 27  VWS (degree)         18159 non-null   float64\n",
      " 28  WD (degree)          149512 non-null  float64\n",
      "dtypes: float64(26), object(2), string(1)\n",
      "memory usage: 62.3+ MB\n"
     ]
    }
   ],
   "source": [
    "state_name = 'Andhra Pradesh'\n",
    "df = combine_state_file(state_name)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have limited memory and processing power, so I clear memory before going further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = %who_ls\n",
    "exclude = ['df', 'np', 'os', 'pd', 'plt', 'sns', 'warnings' 'path', 'exclude', 'l']\n",
    "for d in l:\n",
    "    if d not in exclude:\n",
    "        del globals()[d]\n",
    "\n",
    "del l, exclude, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df', 'np', 'os', 'pd', 'plt', 'sns']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%who_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 272217 entries, 0 to 1592\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   From Date            272217 non-null  object \n",
      " 1   To Date              272217 non-null  object \n",
      " 2   PM2.5 (ug/m3)        215379 non-null  float64\n",
      " 3   PM10 (ug/m3)         218510 non-null  float64\n",
      " 4   NO (ug/m3)           220857 non-null  float64\n",
      " 5   NO2 (ug/m3)          220797 non-null  float64\n",
      " 6   NOx (ppb)            222419 non-null  float64\n",
      " 7   NH3 (ug/m3)          216850 non-null  float64\n",
      " 8   SO2 (ug/m3)          217459 non-null  float64\n",
      " 9   CO (mg/m3)           219063 non-null  float64\n",
      " 10  Ozone (ug/m3)        214914 non-null  float64\n",
      " 11  Benzene (ug/m3)      221629 non-null  float64\n",
      " 12  Toluene (ug/m3)      221602 non-null  float64\n",
      " 13  Temp (degree C)      166170 non-null  float64\n",
      " 14  RH (%)               223812 non-null  float64\n",
      " 15  WS (m/s)             220464 non-null  float64\n",
      " 16  WD (deg)             71726 non-null   float64\n",
      " 17  SR (W/mt2)           221091 non-null  float64\n",
      " 18  BP (mmHg)            165564 non-null  float64\n",
      " 19  VWS (m/s)            206891 non-null  float64\n",
      " 20  Xylene (ug/m3)       168922 non-null  float64\n",
      " 21  RF (mm)              225060 non-null  float64\n",
      " 22  AT (degree C)        223117 non-null  float64\n",
      " 23  city                 272217 non-null  string \n",
      " 24  Eth-Benzene (ug/m3)  39909 non-null   float64\n",
      " 25  MP-Xylene (ug/m3)    105286 non-null  float64\n",
      " 26  O Xylene (ug/m3)     22338 non-null   float64\n",
      " 27  VWS (degree)         18159 non-null   float64\n",
      " 28  WD (degree)          149512 non-null  float64\n",
      "dtypes: float64(26), object(2), string(1)\n",
      "memory usage: 62.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see dataframe includes 272217 rows of data with 28 featrures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{DATA PRCESSING}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe contains two features 'From Date' and 'To Date' that describe one hour windows. The same window is between rows, so I can drop 'To Date' column, because it same information. Since I'm working with time series it's common to use time as index. Let's create a function to make changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_index_creation(df):\n",
    "    df = df.drop(columns= \"To Date\")\n",
    "    df[\"From Date\"] = pd.to_datetime(df[\"From Date\"])\n",
    "    df = df.rename(columns= {\"From Date\": \"datetime\"})\n",
    "    return df.set_index(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5 (ug/m3)</th>\n",
       "      <th>PM10 (ug/m3)</th>\n",
       "      <th>NO (ug/m3)</th>\n",
       "      <th>NO2 (ug/m3)</th>\n",
       "      <th>NOx (ppb)</th>\n",
       "      <th>NH3 (ug/m3)</th>\n",
       "      <th>SO2 (ug/m3)</th>\n",
       "      <th>CO (mg/m3)</th>\n",
       "      <th>Ozone (ug/m3)</th>\n",
       "      <th>Benzene (ug/m3)</th>\n",
       "      <th>...</th>\n",
       "      <th>VWS (m/s)</th>\n",
       "      <th>Xylene (ug/m3)</th>\n",
       "      <th>RF (mm)</th>\n",
       "      <th>AT (degree C)</th>\n",
       "      <th>city</th>\n",
       "      <th>Eth-Benzene (ug/m3)</th>\n",
       "      <th>MP-Xylene (ug/m3)</th>\n",
       "      <th>O Xylene (ug/m3)</th>\n",
       "      <th>VWS (degree)</th>\n",
       "      <th>WD (degree)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01 10:00:00</th>\n",
       "      <td>10.67</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17.67</td>\n",
       "      <td>39.2</td>\n",
       "      <td>32.33</td>\n",
       "      <td>7.07</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.05</td>\n",
       "      <td>Tirupati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 11:00:00</th>\n",
       "      <td>2.00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>41.9</td>\n",
       "      <td>35.80</td>\n",
       "      <td>7.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tirupati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PM2.5 (ug/m3)  PM10 (ug/m3)  NO (ug/m3)  NO2 (ug/m3)  \\\n",
       "datetime                                                                    \n",
       "2016-07-01 10:00:00          10.67          39.0       17.67         39.2   \n",
       "2016-07-01 11:00:00           2.00          39.0       20.50         41.9   \n",
       "\n",
       "                     NOx (ppb)  NH3 (ug/m3)  SO2 (ug/m3)  CO (mg/m3)  \\\n",
       "datetime                                                               \n",
       "2016-07-01 10:00:00      32.33         7.07          6.6        0.48   \n",
       "2016-07-01 11:00:00      35.80         7.40          NaN        0.49   \n",
       "\n",
       "                     Ozone (ug/m3)  Benzene (ug/m3)  ...  VWS (m/s)  \\\n",
       "datetime                                             ...              \n",
       "2016-07-01 10:00:00           14.5              1.0  ...       -0.1   \n",
       "2016-07-01 11:00:00           15.0              0.7  ...       -0.1   \n",
       "\n",
       "                     Xylene (ug/m3)  RF (mm)  AT (degree C)      city  \\\n",
       "datetime                                                                \n",
       "2016-07-01 10:00:00             0.1      0.0          23.05  Tirupati   \n",
       "2016-07-01 11:00:00             0.1      0.0            NaN  Tirupati   \n",
       "\n",
       "                     Eth-Benzene (ug/m3)  MP-Xylene (ug/m3)  O Xylene (ug/m3)  \\\n",
       "datetime                                                                        \n",
       "2016-07-01 10:00:00                  NaN                NaN               NaN   \n",
       "2016-07-01 11:00:00                  NaN                NaN               NaN   \n",
       "\n",
       "                     VWS (degree)  WD (degree)  \n",
       "datetime                                        \n",
       "2016-07-01 10:00:00           NaN          NaN  \n",
       "2016-07-01 11:00:00           NaN          NaN  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_index_creation(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am working with a large dataset, where each file can contain different names for metrics, it will be necessary to reduce some columns by merging potentially similar ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key PM10: ['PM10 (ug/m3)']\n",
      "Key PM2.5: ['PM2.5 (ug/m3)']\n",
      "Key CO: ['CO (mg/m3)']\n",
      "Key NO: ['NO (ug/m3)', 'NO2 (ug/m3)', 'NOx (ppb)']\n",
      "Key NO2: ['NO2 (ug/m3)']\n",
      "Key NOx: ['NOx (ppb)']\n",
      "Key NH3: ['NH3 (ug/m3)']\n",
      "Key SO2: ['SO2 (ug/m3)']\n",
      "Key Temp: ['Temp (degree C)']\n",
      "Key AT: ['AT (degree C)']\n",
      "Key BP: ['BP (mmHg)']\n",
      "Key Benzene: ['Benzene (ug/m3)', 'Eth-Benzene (ug/m3)']\n",
      "Key Eth-Benzene: ['Eth-Benzene (ug/m3)']\n",
      "Key Hg: ['BP (mmHg)']\n",
      "Key MP-Xylene: ['MP-Xylene (ug/m3)']\n",
      "Key O Xylene: ['O Xylene (ug/m3)']\n",
      "Key Ozone: ['Ozone (ug/m3)']\n",
      "Key RF: ['RF (mm)']\n",
      "Key RH: ['RH (%)']\n",
      "Key SR: ['SR (W/mt2)']\n",
      "Key Toluene: ['Toluene (ug/m3)']\n",
      "Key VWS: ['VWS (m/s)', 'VWS (degree)']\n",
      "Key WD: ['WD (deg)', 'WD (degree)']\n",
      "Key WS: ['WS (m/s)', 'VWS (m/s)', 'VWS (degree)']\n",
      "Key Xylene: ['Xylene (ug/m3)', 'MP-Xylene (ug/m3)', 'O Xylene (ug/m3)']\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "    'PM10', 'PM2.5', 'CO', 'CO2', 'NO', 'NO2', 'NOx', 'NH3', 'SO2', 'Temp', 'AT', 'BP', 'Benzene', 'CH4', 'Eth-Benzene', 'Gust', 'HCHO', 'Hg', 'MH', 'MP-Xylene', 'NMHC', 'O Xylene', 'Ozone', 'Power', 'RF', 'RH', 'SPM', 'SR', 'THC', 'Toluene', 'VWS', 'Variance', 'WD', 'WS', 'Xylene'\n",
    "]\n",
    "\n",
    "similar_names = dict()\n",
    "df_column_names = df.columns.to_list()\n",
    "\n",
    "for p in parameters:\n",
    "    for name in df_column_names:\n",
    "\n",
    "        if p not in similar_names:\n",
    "            if p in name:\n",
    "                similar_names[p] = [name]\n",
    "        \n",
    "        else:\n",
    "            if p in name:\n",
    "                similar_names[p].append(name)\n",
    "        \n",
    "\n",
    "for p in similar_names.keys():\n",
    "    #if len(similar_names[p]) > 1:\n",
    "        print(f'Key {p}: {similar_names[p]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after a simple substring search, I found two features that have different units. Now, let's check how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "truly_similar_names = {\n",
    "'VWS': ['VWS (m/s)', 'VWS (degree)'],\n",
    "'WD': ['WD (deg)', 'WD (degree)']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_similarities_lineplot(df: pd.DataFrame, similar_features: dict):\n",
    "    \"\"\"\n",
    "    Function to \n",
    "    \"\"\"\n",
    "    ncol = 2\n",
    "    nrow = int(len(similar_features) /ncol //1)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(13, 6*nrow))\n",
    "\n",
    "    for index, name in enumerate(similar_features):\n",
    "\n",
    "        for _ in similar_features[name]:\n",
    "            df_feature = df[df[_].notnull()][_]\n",
    "            df_feature =df_feature.groupby([df_feature.index.year]).mean(numeric_only=True)\n",
    "\n",
    "            sns.lineplot(data=df_feature, label=_, ax=axes[index])\n",
    "            \n",
    "        axes[index].set_title(name)\n",
    "        axes[index].set(xlabel=None)\n",
    "\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_similarities_histogram(df: pd.DataFrame, similar_feature: list):\n",
    "    \"\"\"\n",
    "    Function show similar_feature for one category grouped by years\n",
    "    Used plot type -> histogram\n",
    "    df - used dataframe\n",
    "    similar_feature -> list of columns to be analysed\n",
    "    \n",
    "    \"\"\"\n",
    "    years = df.index.year.unique().to_list()\n",
    "    \n",
    "    ncol = 2\n",
    "    nrow = int(len(years) /ncol //1)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(13, 6*nrow))\n",
    "\n",
    "    for ind, y in enumerate(years):\n",
    "        df_feature = df[df.index.year == y][similar_feature]\n",
    "        df_feature = df_feature.groupby([df_feature.index.month])\n",
    "\n",
    "\n",
    "\n",
    "    for index, name in enumerate(similar_feature):\n",
    "\n",
    "        for _ in similar_feature[name]:\n",
    "            df_feature = df[df[_].notnull()][_]\n",
    "            df_feature = df_feature[df_feature.index.year == year_]\n",
    "            df_feature =df_feature.groupby([df_feature.index.day]).mean(numeric_only=True)\n",
    "\n",
    "            sns.histplot(data=df_feature, label=_, ax=axes[index], )\n",
    "            \n",
    "        axes[index].set_title(name)\n",
    "        axes[index].set(xlabel=None)\n",
    "\n",
    "    plt.plot()\n",
    "\n",
    "    #plot_features_similarities_lineplot(df, truly_similar_names)\\\n",
    "d = df[df.index.year == 2019][['WD (deg)', 'WD (degree)']]\n",
    "d.groupby([d.index.]).mean(numeric_only = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WD (deg)</th>\n",
       "      <th>WD (degree)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181.118230</td>\n",
       "      <td>178.515084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.157862</td>\n",
       "      <td>185.575971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172.917822</td>\n",
       "      <td>188.698634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178.132636</td>\n",
       "      <td>183.322897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>181.954152</td>\n",
       "      <td>190.737360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>177.370957</td>\n",
       "      <td>189.443424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>171.544647</td>\n",
       "      <td>193.197965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>175.422328</td>\n",
       "      <td>188.973822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167.528326</td>\n",
       "      <td>186.924737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>177.168865</td>\n",
       "      <td>187.434104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>176.910519</td>\n",
       "      <td>182.047569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>186.930273</td>\n",
       "      <td>178.829326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>188.591576</td>\n",
       "      <td>175.228852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>191.977261</td>\n",
       "      <td>181.827214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>199.242652</td>\n",
       "      <td>175.315070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>210.261408</td>\n",
       "      <td>171.707513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>215.306721</td>\n",
       "      <td>176.198444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202.115057</td>\n",
       "      <td>170.946440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>197.899085</td>\n",
       "      <td>166.842711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>186.994200</td>\n",
       "      <td>167.271945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>195.043356</td>\n",
       "      <td>163.268010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>193.046245</td>\n",
       "      <td>173.550227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>187.025286</td>\n",
       "      <td>183.459935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>174.325982</td>\n",
       "      <td>179.675750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>172.659655</td>\n",
       "      <td>174.974677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>170.477656</td>\n",
       "      <td>171.260858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>181.689194</td>\n",
       "      <td>177.250286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>182.849666</td>\n",
       "      <td>179.363538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>178.933614</td>\n",
       "      <td>179.895765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>186.831415</td>\n",
       "      <td>179.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>180.981763</td>\n",
       "      <td>170.121416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WD (deg)  WD (degree)\n",
       "datetime                         \n",
       "1         181.118230   178.515084\n",
       "2         175.157862   185.575971\n",
       "3         172.917822   188.698634\n",
       "4         178.132636   183.322897\n",
       "5         181.954152   190.737360\n",
       "6         177.370957   189.443424\n",
       "7         171.544647   193.197965\n",
       "8         175.422328   188.973822\n",
       "9         167.528326   186.924737\n",
       "10        177.168865   187.434104\n",
       "11        176.910519   182.047569\n",
       "12        186.930273   178.829326\n",
       "13        188.591576   175.228852\n",
       "14        191.977261   181.827214\n",
       "15        199.242652   175.315070\n",
       "16        210.261408   171.707513\n",
       "17        215.306721   176.198444\n",
       "18        202.115057   170.946440\n",
       "19        197.899085   166.842711\n",
       "20        186.994200   167.271945\n",
       "21        195.043356   163.268010\n",
       "22        193.046245   173.550227\n",
       "23        187.025286   183.459935\n",
       "24        174.325982   179.675750\n",
       "25        172.659655   174.974677\n",
       "26        170.477656   171.260858\n",
       "27        181.689194   177.250286\n",
       "28        182.849666   179.363538\n",
       "29        178.933614   179.895765\n",
       "30        186.831415   179.730769\n",
       "31        180.981763   170.121416"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot_features_similarities_lineplot(df, truly_similar_names)\\\n",
    "d = df[df.index.year == 2019][['WD (deg)', 'WD (degree)']]\n",
    "d.groupby([d.index.]).mean(numeric_only = True)\n",
    "#aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VWS (m/s)</th>\n",
       "      <td>206891.000</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.690</td>\n",
       "      <td>-19.460</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>19.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VWS (degree)</th>\n",
       "      <td>18159.000</td>\n",
       "      <td>4.824</td>\n",
       "      <td>0.917</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD (deg)</th>\n",
       "      <td>71726.000</td>\n",
       "      <td>184.421</td>\n",
       "      <td>78.057</td>\n",
       "      <td>0.200</td>\n",
       "      <td>130.750</td>\n",
       "      <td>183.100</td>\n",
       "      <td>239.000</td>\n",
       "      <td>360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD (degree)</th>\n",
       "      <td>149512.000</td>\n",
       "      <td>182.865</td>\n",
       "      <td>72.489</td>\n",
       "      <td>2.610</td>\n",
       "      <td>120.000</td>\n",
       "      <td>180.670</td>\n",
       "      <td>246.750</td>\n",
       "      <td>360.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count     mean     std      min      25%      50%      75%  \\\n",
       "VWS (m/s)     206891.000   -0.010   0.690  -19.460   -0.050    0.000    0.040   \n",
       "VWS (degree)   18159.000    4.824   0.917   -0.060    5.000    5.000    5.000   \n",
       "WD (deg)       71726.000  184.421  78.057    0.200  130.750  183.100  239.000   \n",
       "WD (degree)   149512.000  182.865  72.489    2.610  120.000  180.670  246.750   \n",
       "\n",
       "                  max  \n",
       "VWS (m/s)      19.680  \n",
       "VWS (degree)    5.000  \n",
       "WD (deg)      360.000  \n",
       "WD (degree)   360.000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[_ for item in truly_similar_names.values() for _ in item]].describe().applymap(lambda x: f\"{x:0.3f}\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_features_similarities_histogram() got an unexpected keyword argument 'year_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_features_similarities_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruly_similar_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2019\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_features_similarities_histogram() got an unexpected keyword argument 'year_'"
     ]
    }
   ],
   "source": [
    "plot_features_similarities_histogram(df, truly_similar_names, year_ = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     VWS (m/s)  VWS (degree)\n",
      "datetime                                    \n",
      "2016-07-01 10:00:00       True         False\n",
      "2016-07-01 11:00:00       True         False\n",
      "2016-07-01 12:00:00      False         False\n",
      "2016-07-01 13:00:00      False         False\n",
      "2016-07-01 14:00:00       True         False\n",
      "...                        ...           ...\n",
      "2023-03-31 19:00:00       True         False\n",
      "2023-03-31 20:00:00       True         False\n",
      "2023-03-31 21:00:00       True         False\n",
      "2023-03-31 22:00:00       True         False\n",
      "2023-03-31 23:00:00       True         False\n",
      "\n",
      "[272217 rows x 2 columns]\n",
      "                     WD (deg)  WD (degree)\n",
      "datetime                                  \n",
      "2016-07-01 10:00:00      True        False\n",
      "2016-07-01 11:00:00      True        False\n",
      "2016-07-01 12:00:00     False        False\n",
      "2016-07-01 13:00:00     False        False\n",
      "2016-07-01 14:00:00      True        False\n",
      "...                       ...          ...\n",
      "2023-03-31 19:00:00     False         True\n",
      "2023-03-31 20:00:00     False         True\n",
      "2023-03-31 21:00:00     False         True\n",
      "2023-03-31 22:00:00     False         True\n",
      "2023-03-31 23:00:00     False         True\n",
      "\n",
      "[272217 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in truly_similar_names.keys():\n",
    "     \n",
    "    print(df[truly_similar_names[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the histogram, dataframe.describe and lineplot I can say that WD features are similar in most years (differences appears because of lack of data), not like VWS.\n",
    "I was able to merge the following features. The rest have too many missing values so we are going to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_n_marge_feature = {\n",
    " 'PM10': ['PM10 (ug/m3)'],\n",
    " 'PM2.5': ['PM2.5 (ug/m3)'],\n",
    " 'CO': ['CO (mg/m3)'],\n",
    " 'NO': ['NO (ug/m3)'],\n",
    " 'NO2': ['NO2 (ug/m3)'],\n",
    " 'NOx': ['NOx (ppb)'],\n",
    " 'NH3': ['NH3 (ug/m3)'],\n",
    " 'SO2': ['SO2 (ug/m3)'],\n",
    " 'Temp': ['Temp (degree C)'],\n",
    " 'AT': ['AT (degree C)'],\n",
    " 'BP': ['BP (mmHg)'],\n",
    " 'Benzene': ['Benzene (ug/m3)'],\n",
    " 'Eth-Benzene': ['Eth-Benzene (ug/m3)'],\n",
    " 'MP-Xylene': ['MP-Xylene (ug/m3)'],\n",
    " 'O Xylene': ['O Xylene (ug/m3)'],\n",
    " 'Ozone': ['Ozone (ug/m3)'],\n",
    " 'RF': ['RF (mm)'],\n",
    " 'RH': ['RH (%)'],\n",
    " 'SR': ['SR (W/mt2)'],\n",
    " 'Toluene': ['Toluene (ug/m3)'],\n",
    " 'VWS': ['VWS (m/s)'],\n",
    " 'WD': ['WD (deg)', 'WD (degree)'],\n",
    " 'WS': ['WS (m/s)'],\n",
    " 'Xylene': ['Xylene (ug/m3)']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch\n"
     ]
    }
   ],
   "source": [
    "def marge_features(df, features_to_marge):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Exploratory Data Analysis (EDA)}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

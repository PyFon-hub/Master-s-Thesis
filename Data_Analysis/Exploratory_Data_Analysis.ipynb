{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{LIBRARIES}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_print(): print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_name', 'state', 'city', 'agency', 'station_location',\n",
      "       'start_month', 'start_month_num', 'start_year'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "  file_name           state        city agency          station_location  \\\n",
      "0     AP001  Andhra Pradesh    Tirupati  APPCB       Tirumala, Tirupati    \n",
      "1     AP002  Andhra Pradesh  Vijayawada  APPCB  PWD Grounds, Vijayawada    \n",
      "\n",
      "  start_month  start_month_num  start_year  \n",
      "0        July                7        2016  \n",
      "1         May                5        2017  \n"
     ]
    }
   ],
   "source": [
    "df_states = pd.read_csv(path + 'stations_info.csv')\n",
    "print(df_states.columns)\n",
    "\n",
    "sep_print()\n",
    "print(df_states.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a lot of data, so we're going to choose only one state for analysis. \n",
    "I'm looking for the state that has the minimum number of agencies (each agency can have different measurements or columns name for the same feature, so choosing one will be easier) and the most data available and similar number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dict = dict()\n",
    "max_dict = dict()\n",
    "min_dict = dict()\n",
    "\n",
    "for i in os.listdir(path):\n",
    "\n",
    "    if not i.endswith(\".csv\"):\n",
    "        next\n",
    "\n",
    "    prefix = i[:2]\n",
    "    val = pd.read_csv(path + i, nrows= 1).shape[1]\n",
    "\n",
    "    if prefix in sum_dict:\n",
    "            sum_dict[prefix] += val\n",
    "            max_dict[prefix] = val if max_dict[prefix] < val else  max_dict[prefix]\n",
    "            min_dict[prefix] = val if min_dict[prefix] > val else  min_dict[prefix]\n",
    "    else:\n",
    "        sum_dict[prefix] = val\n",
    "        max_dict[prefix] = val\n",
    "        min_dict[prefix] = val\n",
    "\n",
    "#Number of all columns in each state and max/ min number of column\n",
    "smm_df = pd.DataFrame({'sum': sum_dict.values(), 'min': min_dict.values(), 'max': max_dict.values()}, index=sum_dict.keys()).sort_values(by= [\"sum\", \"min\", \"max\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             count_agency  count_csv  sum  min  max\n",
      "file_name state                                                    \n",
      "HP        Himachal Pradesh              1          1   23   23   23\n",
      "JK        Jammu and Kashmir             1          1   23   23   23\n",
      "MZ        Mizoram                       1          1   23   23   23\n",
      "NL        Nagaland                      1          1   23   23   23\n",
      "SK        Sikkim                        1          1   24   24   24\n",
      "AR        Arunachal Pradesh             1          1   25   25   25\n",
      "PY        Puducherry                    1          1   25   25   25\n",
      "JH        Jharkhand                     1          2   29   10   19\n",
      "TR        Tripura                       1          2   47   23   24\n",
      "MN        Manipur                       1          2   48   24   24\n",
      "ML        Meghalaya                     1          2   49   24   25\n",
      "UK        Uttarakhand                   1          3   66   16   25\n",
      "CH        Chandigarh                    1          3   70   23   24\n",
      "KL        Kerala                        1          9  176   15   22\n",
      "AS        Assam                         1          9  206   22   24\n",
      "AP        Andhra Pradesh                1         10  241   23   25\n",
      "OR        Odisha                        1         12  233    9   24\n",
      "TG        Telangana                     1         14  319   20   23\n",
      "WB        West Bengal                   1         14  338   20   26\n",
      "BR        Bihar                         1         35  818   20   25\n",
      "RJ        Rajasthan                     1         35  818   22   24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ziewi\\AppData\\Local\\Temp\\ipykernel_46088\\3135209361.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_states_sub[\"file_name\"] = df_states_sub[\"file_name\"].apply(lambda x: x[:2])\n"
     ]
    }
   ],
   "source": [
    "#Number of diffrent agencies that measure air quility and how many .csv\n",
    "df_states_sub = df_states[[\"file_name\", \"state\", \"agency\"]]\n",
    "df_states_sub[\"file_name\"] = df_states_sub[\"file_name\"].apply(lambda x: x[:2])\n",
    "\n",
    "df_states_sub_info = df_states_sub[[\"file_name\", \"state\", \"agency\"]].drop_duplicates().groupby([\"file_name\", \"state\"]).count()\n",
    "df_states_sub_info = df_states_sub_info.join(\n",
    "                pd.value_counts(df_states[\"state\"]),\n",
    "                on = \"state\"\n",
    "            ).join(\n",
    "                smm_df,\n",
    "                on = \"file_name\"\n",
    "            )\n",
    "\n",
    "#Column rename\n",
    "df_states_sub_info.columns = ['count_agency', 'count_csv', 'sum', 'min', 'max']\n",
    "\n",
    "#Combining all created data\n",
    "df_states_sub_info = df_states_sub_info.sort_values(['count_agency', 'count_csv', 'sum', 'min', 'max'], kind= 'heapsort')\n",
    "print(df_states_sub_info[df_states_sub_info.count_agency == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output I chose Andhra Pradesh state. The reason is that this state have 10 .csv files within 23 to 25 column with data.\n",
    "Rajasthan state could work too but my laptop wouldn't have been able to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_name           state        city  start_month_num  start_year\n",
      "0     AP001  Andhra Pradesh    Tirupati                7        2016\n",
      "1     AP002  Andhra Pradesh  Vijayawada                5        2017\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_states.drop(columns= [\"agency\", \"station_location\", \"start_month\"], inplace= True)\n",
    "except:\n",
    "    pass\n",
    "print(df_states.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tirupati', 'Vijayawada', 'Visakhapatnam', 'Rajamahendravaram',\n",
       "       'Amaravati', 'Anantapur', 'Chittoor', 'Kadapa'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states[df_states['state'] == 'Andhra Pradesh'].city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with a large dataset which is split in multiple files. \n",
    "First I will create a function that will return a dataframe combining all datasheets measurements in a given state, so will see what data I'm working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_state_file(state_name: str):\n",
    "    file_name_short = df_states_sub[df_states_sub[\"state\"] == state_name][\"file_name\"]\n",
    "\n",
    "    global path\n",
    "    combined_df = list()\n",
    "\n",
    "    print(f\"Combining a total of {len(file_name_short)} files\")\n",
    "\n",
    "    file_name_short = file_name_short.iloc[0]\n",
    "\n",
    "    for file in  os.listdir(path):\n",
    "        if file_name_short in file:\n",
    "            print(file)\n",
    "\n",
    "            file_data = pd.read_csv(path + file)\n",
    "            file_data[\"city\"] = df_states[df_states[\"file_name\"] == file[:-4]][\"city\"].values[0]\n",
    "            file_data[\"city\"] = file_data[\"city\"].astype(\"string\")\n",
    "\n",
    "            combined_df.append(file_data)\n",
    "\n",
    "    return pd.concat(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining a total of 10 files\n",
      "AP001.csv\n",
      "AP002.csv\n",
      "AP003.csv\n",
      "AP004.csv\n",
      "AP005.csv\n",
      "AP006.csv\n",
      "AP007.csv\n",
      "AP008.csv\n",
      "AP009.csv\n",
      "AP010.csv\n"
     ]
    }
   ],
   "source": [
    "state_name = 'Andhra Pradesh'\n",
    "df = combine_state_file(state_name)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have limited memory and processing power, so I clear memory before going futher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = %who_ls\n",
    "exclude = ['df', 'np', 'os', 'pd', 'plt', 'sns', 'warnings' 'path', 'exclude', 'l']\n",
    "for d in l:\n",
    "    if d not in exclude:\n",
    "        del globals()[d]\n",
    "\n",
    "del l, exclude, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'df', 'np', 'os', 'pd', 'plt', 'sns', 'val']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%who_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 272217 entries, 0 to 1592\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   From Date            272217 non-null  object \n",
      " 1   To Date              272217 non-null  object \n",
      " 2   PM2.5 (ug/m3)        215379 non-null  float64\n",
      " 3   PM10 (ug/m3)         218510 non-null  float64\n",
      " 4   NO (ug/m3)           220857 non-null  float64\n",
      " 5   NO2 (ug/m3)          220797 non-null  float64\n",
      " 6   NOx (ppb)            222419 non-null  float64\n",
      " 7   NH3 (ug/m3)          216850 non-null  float64\n",
      " 8   SO2 (ug/m3)          217459 non-null  float64\n",
      " 9   CO (mg/m3)           219063 non-null  float64\n",
      " 10  Ozone (ug/m3)        214914 non-null  float64\n",
      " 11  Benzene (ug/m3)      221629 non-null  float64\n",
      " 12  Toluene (ug/m3)      221602 non-null  float64\n",
      " 13  Temp (degree C)      166170 non-null  float64\n",
      " 14  RH (%)               223812 non-null  float64\n",
      " 15  WS (m/s)             220464 non-null  float64\n",
      " 16  WD (deg)             71726 non-null   float64\n",
      " 17  SR (W/mt2)           221091 non-null  float64\n",
      " 18  BP (mmHg)            165564 non-null  float64\n",
      " 19  VWS (m/s)            206891 non-null  float64\n",
      " 20  Xylene (ug/m3)       168922 non-null  float64\n",
      " 21  RF (mm)              225060 non-null  float64\n",
      " 22  AT (degree C)        223117 non-null  float64\n",
      " 23  city                 272217 non-null  string \n",
      " 24  Eth-Benzene (ug/m3)  39909 non-null   float64\n",
      " 25  MP-Xylene (ug/m3)    105286 non-null  float64\n",
      " 26  O Xylene (ug/m3)     22338 non-null   float64\n",
      " 27  VWS (degree)         18159 non-null   float64\n",
      " 28  WD (degree)          149512 non-null  float64\n",
      "dtypes: float64(26), object(2), string(1)\n",
      "memory usage: 62.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{DATA PRCESSING}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Exploratory Data Analysis (EDA)}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
